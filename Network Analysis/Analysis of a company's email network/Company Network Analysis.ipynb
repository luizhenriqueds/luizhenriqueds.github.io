{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing a company's email network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Company Emails\n",
    "\n",
    "In this project we will be workking with a company's email network where each node corresponds to a person at the company, and each edge indicates that at least one email has been sent between two people.\n",
    "\n",
    "The network also contains the node attributes `Department` and `ManagmentSalary`.\n",
    "\n",
    "`Department` indicates the department in the company which the person belongs to, and `ManagmentSalary` indicates whether that person is receiving a managment position salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: Graph\n",
      "Number of nodes: 1005\n",
      "Number of edges: 16706\n",
      "Average degree:  33.2458\n"
     ]
    }
   ],
   "source": [
    "# Loading the graph\n",
    "G = nx.read_gpickle('email_prediction.txt')\n",
    "\n",
    "# Printing graph info\n",
    "print(nx.info(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salary Prediction\n",
    "\n",
    "Using network `G`, we will identify the people in the network with missing values for the node attribute `ManagementSalary` and predict whether or not these individuals are receiving a managment position salary.\n",
    "\n",
    "To accomplish this, we will need to create a matrix of node features using networkx, train a sklearn classifier on nodes that have `ManagementSalary` data, and predict a probability of the node receiving a managment salary for nodes where `ManagementSalary` is missing.\n",
    "\n",
    "\n",
    "Our predictions will need to be given as the probability that the corresponding employee is receiving a managment position salary.\n",
    "\n",
    "The evaluation metric for this project is the Area Under the ROC Curve (AUC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def salary_predictions():\n",
    "    \n",
    "    '''\n",
    "        Description: This function calculates the probability of an employee being receiving a management salary.\n",
    "        \n",
    "        Args:\n",
    "            - N/A\n",
    "        \n",
    "        Returns: \n",
    "            - predictions (Series): the list of probability of the employee being receiving a management salary\n",
    "    '''\n",
    "    \n",
    "    # A list to store graph properties\n",
    "    mngnt_salary = []\n",
    "\n",
    "    # Iterating over the graph nodes\n",
    "    for item in G.nodes_iter(data=True):\n",
    "        # Storing the values for each node\n",
    "        mngnt_salary.append({'Department':item[1]['Department'], 'ManagementSalary': item[1]['ManagementSalary']})\n",
    "    # Creating a dataframe from list\n",
    "    df_salary = pd.DataFrame(mngnt_salary)\n",
    "\n",
    "    # Creating a column with 'clustering' graph property\n",
    "    df_salary['clustering'] = pd.Series(nx.clustering(G))\n",
    "    \n",
    "    # Creating a column with 'degree' graph property\n",
    "    df_salary['degree'] = pd.Series(G.degree())\n",
    "    \n",
    "    # Creating a column with 'closeness_centrality' graph property\n",
    "    df_salary['closeness'] = pd.Series(nx.closeness_centrality(G))\n",
    "    \n",
    "    # Creating a column with 'betweenness_centrality' graph property\n",
    "    df_salary['betweness'] = pd.Series(nx.betweenness_centrality(G))\n",
    "\n",
    "    # Cloning the original dataframe\n",
    "    df_missing = df_salary.copy()\n",
    "    \n",
    "    # Filtering the entries where 'ManagementSalary' is missing\n",
    "    df_missing = df_missing[np.isnan(df_missing['ManagementSalary'])]\n",
    "    \n",
    "    # Drop NA values\n",
    "    df_salary.dropna(inplace=True)\n",
    "    \n",
    "    # Selecting X features\n",
    "    X = df_salary[['clustering', 'degree', 'closeness',\n",
    "       'betweness']]\n",
    "    \n",
    "    # Selecting target feature\n",
    "    y = df_salary['ManagementSalary']\n",
    "\n",
    "    # Selecting employees which we want to predict the salary\n",
    "    X_pred = df_missing[['clustering', 'degree', 'closeness',\n",
    "           'betweness']]\n",
    "\n",
    "    # Splitting data into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "    # Applying Standard Scaler to normalize the data\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test) \n",
    "    X_pred = scaler.transform(X_pred) \n",
    "\n",
    "    # Training a SVC model\n",
    "    svc_model = SVC(C=10, probability=True, random_state=42).fit(X_train, y_train)\n",
    "    \n",
    "    # Traninng a KNN model\n",
    "    knn_classifier = KNeighborsClassifier().fit(X_train, y_train)\n",
    "    \n",
    "    # Training a Logistic Regression Model\n",
    "    logistic_reg = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "    # Predicting the probability of the person being receiving a management salary\n",
    "    model_pred = logistic_reg.predict_proba(X_pred)\n",
    "    \n",
    "    # Storing the predictions\n",
    "    predictions = pd.Series(model_pred[:, 1], index=df_missing.index)\n",
    "    \n",
    "    # Returning the list of probabilities\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Connections Prediction\n",
    "\n",
    "In this part of this project, you will predict future connections between employees of the network. The future connections information has been loaded into the variable `future_connections`. The index is a tuple indicating a pair of nodes that currently do not have a connection, and the `Future Connection` column indicates if an edge between those two nodes will exist in the future, where a value of 1.0 indicates a future connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Future Connection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(6, 840)</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(4, 197)</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(620, 979)</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(519, 872)</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(382, 423)</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(97, 226)</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(349, 905)</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(429, 860)</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(309, 989)</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(468, 880)</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Future Connection\n",
       "(6, 840)                  0.0\n",
       "(4, 197)                  0.0\n",
       "(620, 979)                0.0\n",
       "(519, 872)                0.0\n",
       "(382, 423)                0.0\n",
       "(97, 226)                 1.0\n",
       "(349, 905)                0.0\n",
       "(429, 860)                0.0\n",
       "(309, 989)                0.0\n",
       "(468, 880)                0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data\n",
    "future_connections = pd.read_csv('Future_Connections.csv', index_col=0, converters={0: eval})\n",
    "\n",
    "# Showing top 10 entries\n",
    "future_connections.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using network `G` and `future_connections`, we will identify the edges in `future_connections` with missing values and predict whether or not these edges will have a future connection.\n",
    "\n",
    "To accomplish this, we will need to create a matrix of features for the edges found in `future_connections` using networkx, train a sklearn classifier on those edges in `future_connections` that have `Future Connection` data, and predict a probability of the edge being a future connection for those edges in `future_connections` where `Future Connection` is missing.\n",
    "\n",
    "The evaluation metric for this project is the Area Under the ROC Curve (AUC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_connections_predictions():\n",
    "    \n",
    "    '''\n",
    "        Description: This function calculates the probability of employees being a future connection in a company's email network.\n",
    "        \n",
    "        Args:\n",
    "            - N/A\n",
    "        \n",
    "        Returns: \n",
    "            - predictions (Series): the edges probabilities of employees being a future connection\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Adding 'preferencial attachement' graph attribute to the dataframe\n",
    "    future_connections['Preferential Attachment'] = [i[2] for i in nx.preferential_attachment(G, future_connections.index)]\n",
    "    \n",
    "    # Adding 'common neighbors' graph attribute to the dataframe\n",
    "    future_connections['Common Neighbors'] = future_connections.index.map(lambda empl: len(list(nx.common_neighbors(G, empl[0], empl[1]))))\n",
    "\n",
    "    # Cloning the original dataframe\n",
    "    ft_mising = future_connections.copy()\n",
    "    \n",
    "    # Filtering the entries where 'ManagementSalary' is missing\n",
    "    ft_mising = ft_mising[np.isnan(ft_mising['Future Connection'])]\n",
    "    \n",
    "    # Drop NA values\n",
    "    future_connections.dropna(inplace=True)\n",
    "    \n",
    "    # Selecting predictor features\n",
    "    X = future_connections[['Preferential Attachment', 'Common Neighbors']]\n",
    "    \n",
    "    # Selecting target feature\n",
    "    y = future_connections['Future Connection']\n",
    "    \n",
    "    # Selecting entries which we want to predict edgde probability of being a future connection\n",
    "    X_pred = ft_mising[['Preferential Attachment', 'Common Neighbors']]\n",
    "    \n",
    "    # Splitting the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "    # Applying Standard Scaler to normalize the data\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test) \n",
    "    X_pred = scaler.transform(X_pred) \n",
    "\n",
    "    # Training a Logistic Regression Model\n",
    "    logistic_reg = LogisticRegression().fit(X_train, y_train)\n",
    "    \n",
    "    # Predicting the probability of employees being a future connection\n",
    "    ft_predictions = logistic_reg.predict_proba(X_pred)\n",
    "    \n",
    "     # Storing the predictions\n",
    "    predictions = pd.Series(ft_predictions[:, 1], index=ft_mising.index)\n",
    "\n",
    "    # Returning the predictions probabilities\n",
    "    return predictions"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-social-network-analysis",
   "graded_item_id": "BGNwe",
   "launcher_item_id": "rMoj0",
   "part_id": "E2zRG"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
