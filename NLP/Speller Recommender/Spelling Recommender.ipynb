{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spelling Recommender\n",
    "\n",
    "For this project, we will create three different spelling recommenders, that each take a list of misspelled words and recommends a correctly spelled word for every word in the list.\n",
    "\n",
    "For every misspelled word, the recommender should find find the word in `correct_spellings` that has the shortest distance*, and starts with the same letter as the misspelled word, and return that word as a recommendation.\n",
    "\n",
    "*Each of the three different recommenders will use a different distance measure (outlined below).\n",
    "\n",
    "Each of the recommenders should provide recommendations for the three default words provided: `['cormulent', 'incendenece', 'validrate']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "from nltk.corpus import words\n",
    "\n",
    "# Loading a vocabulary with 'corrected words'\n",
    "correct_spellings = words.words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommender using Jaccard distance\n",
    "\n",
    "For this recommender, your function should provide recommendations for the three default words provided above using the following distance metric:\n",
    "\n",
    "**[Jaccard distance](https://en.wikipedia.org/wiki/Jaccard_index) on the trigrams of the two words.**\n",
    "\n",
    "*This function should return a list of length three:\n",
    "`['cormulent_reccomendation', 'incendenece_reccomendation', 'validrate_reccomendation']`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ngrams_3(text, n):\n",
    "    \n",
    "    '''\n",
    "        Description: This function receives a text and the number of n-grams to extract from it.\n",
    "        \n",
    "        Args: \n",
    "            - text (string): the target text\n",
    "            - n (int): the number of n-grams to extract from the input text\n",
    "        \n",
    "        Returns: \n",
    "            - joined_n_grams (string): the joined n-grams extracted from the original text\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Applying n-gram in nltk\n",
    "    n_grams = nltk.ngrams(text, n)\n",
    "    \n",
    "    # Joining tokens\n",
    "    joined_n_grams = [ ' '.join(grams) for grams in n_grams]\n",
    "    \n",
    "    # Returning string with joined tokens\n",
    "    return joined_n_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel/__main__.py:3: DeprecationWarning: generator 'ngrams' raised StopIteration\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['corpulent', 'indecence', 'validate']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def recommender_jaccard_3_grams(entries=['cormulent', 'incendenece', 'validrate']):\n",
    "    \n",
    "    '''\n",
    "        Description: This function receives three misspelled words and apply the Jaccard distance to them with 3-grams to recommend the corrected word for each one.\n",
    "        \n",
    "        Args:\n",
    "            - entries (list): a list of length three with the misspelled words\n",
    "        \n",
    "        Returns:\n",
    "            - result_list (list): a list of length three: ['cormulent_reccomendation', 'incendenece_reccomendation', 'validrate_reccomendation']\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Load the vocabulary\n",
    "    dictionary = [w for w in correct_spellings if w[0].lower() == entries[0][0].lower() or w[0].lower() == entries[1][0].lower()\n",
    "                  or w[0].lower() == entries[2][0].lower()]\n",
    "    \n",
    "    # List to append recommendations for the first word\n",
    "    cols = []\n",
    "    \n",
    "    # List to append recommendations for the second word\n",
    "    cols2 = []\n",
    "    \n",
    "    # List to append recommendations for the third word\n",
    "    cols3 = []\n",
    "    \n",
    "    # Iterating over the dictionary to find similar items to the fisrt word\n",
    "    for the_item in dictionary:\n",
    "        # Applying the 3-gram to the first misspelled word\n",
    "        set1 = get_ngrams_3(entries[0], 3)\n",
    "        \n",
    "        # Apllying the 3-gram to each item of the vocabulary of corrected words\n",
    "        set2 = get_ngrams_3(the_item, 3)\n",
    "        \n",
    "        # Calculating the Jaccard distance for each word\n",
    "        res = nltk.distance.jaccard_distance(set(set1),set(set2))\n",
    "        \n",
    "        # Appending the word and its respective distance to the list\n",
    "        cols.append({\"word\": the_item, \"distance\": float(res.real)})\n",
    "        \n",
    "    # Generating a dataframe from the previous list\n",
    "    df1 = pd.DataFrame(cols)\n",
    "\n",
    "    # Iterating over the dictionary to find similar items to the second word\n",
    "    for the_item in dictionary:\n",
    "        # Applying the 3-gram to the second misspelled word\n",
    "        set1 = get_ngrams_3(entries[1], 3)\n",
    "        \n",
    "        # Apllying the 3-gram to each item of the vocabulary of corrected words\n",
    "        set2 = get_ngrams_3(the_item, 3)\n",
    "        \n",
    "        # Calculating the Jaccard distance for each word\n",
    "        res = nltk.distance.jaccard_distance(set(set1),set(set2))\n",
    "        \n",
    "        # Appending the word and its respective distance to the list\n",
    "        cols2.append({\"word\": the_item, \"distance\": float(res.real)})\n",
    "        \n",
    "    # Generating a dataframe from the previous list\n",
    "    df2 = pd.DataFrame(cols2)\n",
    "\n",
    "    # Iterating over the dictionary to find similar items to the third word\n",
    "    for the_item in dictionary:\n",
    "        # Applying the 3-gram to the third misspelled word\n",
    "        set1 = get_ngrams_3(entries[2], 3)\n",
    "        \n",
    "        # Apllying the 3-gram to each item of the vocabulary of corrected words\n",
    "        set2 = get_ngrams_3(the_item, 3)\n",
    "        \n",
    "        # Calculating the Jaccard distance for each word\n",
    "        res = nltk.distance.jaccard_distance(set(set1),set(set2))\n",
    "        \n",
    "        # Appending the word and its respective distance to the list\n",
    "        cols3.append({\"word\": the_item, \"distance\": float(res.real)})\n",
    "    \n",
    "    # Generating a dataframe from the previous list\n",
    "    df3 = pd.DataFrame(cols3)\n",
    "    \n",
    "    # Appending the recommendation for each misspelled word to the result list\n",
    "    result_list = [df1.sort_values('distance')['word'].values[0],\n",
    "            df2.sort_values('distance')['word'].values[0],\n",
    "            df3.sort_values('distance')['word'].values[0]]\n",
    "\n",
    "    # Returning the result list\n",
    "    return result_list\n",
    "    \n",
    "recommender_jaccard_3_grams()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this recommender, your function should provide recommendations for the three default words provided above using the following distance metric:\n",
    "\n",
    "**[Jaccard distance](https://en.wikipedia.org/wiki/Jaccard_index) on the 4-grams of the two words.**\n",
    "\n",
    "*This function should return a list of length three:\n",
    "`['cormulent_reccomendation', 'incendenece_reccomendation', 'validrate_reccomendation']`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ngrams_4(text, n):\n",
    "    \n",
    "    '''\n",
    "        Description: This function receives a text and the number of n-grams to extract from it.\n",
    "        \n",
    "        Args: \n",
    "            - text (string): the target text\n",
    "            - n (int): the number of n-grams to extract from the input text\n",
    "        \n",
    "        Returns: \n",
    "            - joined_n_grams (string): the joined n-grams extracted from the original text\n",
    "    \n",
    "    '''\n",
    "    # Applying n-gram in nltk\n",
    "    n_grams = nltk.ngrams(text, n)\n",
    "    \n",
    "    # Joining tokens\n",
    "    joined_n_grams = [ ' '.join(grams) for grams in n_grams]\n",
    "    \n",
    "    return joined_n_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel/__main__.py:3: DeprecationWarning: generator 'ngrams' raised StopIteration\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['cormus', 'incendiary', 'valid']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def recommender_jaccard_4_grams(entries=['cormulent', 'incendenece', 'validrate']):\n",
    "    \n",
    "    '''\n",
    "        Description: This function receives three misspelled words and apply the Jaccard distance to them with 4-grams to recommend the corrected word for each one.\n",
    "        \n",
    "        Args:\n",
    "            - entries (list): a list of length three with the misspelled words\n",
    "        \n",
    "        Returns:\n",
    "            - result_list (list): a list of length three: ['cormulent_reccomendation', 'incendenece_reccomendation', 'validrate_reccomendation']\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Load the dictionary\n",
    "    dictionary = [w for w in correct_spellings if w[0].lower() == entries[0][0].lower() or w[0].lower() == entries[1][0].lower()\n",
    "                  or w[0].lower() == entries[2][0].lower()]\n",
    "    \n",
    "    # List to append recommendations for the first word\n",
    "    cols = []\n",
    "    \n",
    "    # List to append recommendations for the second word\n",
    "    cols2 = []\n",
    "    \n",
    "    # List to append recommendations for the third word\n",
    "    cols3 = []\n",
    "    \n",
    "    # Iterating over the dictionary to find similar items to the fisrt word\n",
    "    for the_item in dictionary:\n",
    "        # Applying the 4-gram to the first misspelled word\n",
    "        set1 = get_ngrams_4(entries[0], 4)\n",
    "        \n",
    "        # Apllying the 4-gram to each item of the vocabulary of corrected words\n",
    "        set2 = get_ngrams_4(the_item, 4)\n",
    "        \n",
    "        # Calculating the Jaccard distance for each word\n",
    "        res = nltk.distance.jaccard_distance(set(set1),set(set2))\n",
    "        \n",
    "        # Appending the word and its respective distance to the list\n",
    "        cols.append({\"word\": the_item, \"distance\": float(res.real)})\n",
    "    \n",
    "    # Generating a dataframe from the previous list\n",
    "    df1 = pd.DataFrame(cols)\n",
    "\n",
    "    # Iterating over the dictionary to find similar items to the second word\n",
    "    for the_item in dictionary:\n",
    "        # Applying the 4-gram to the second misspelled word\n",
    "        set1 = get_ngrams_4(entries[1], 4)\n",
    "        \n",
    "        # Apllying the 4-gram to each item of the vocabulary of corrected words\n",
    "        set2 = get_ngrams_4(the_item, 4)\n",
    "        \n",
    "        # Calculating the Jaccard distance for each word\n",
    "        res = nltk.distance.jaccard_distance(set(set1),set(set2))\n",
    "        \n",
    "        # Appending the word and its respective distance to the list\n",
    "        cols2.append({\"word\": the_item, \"distance\": float(res.real)})\n",
    "    \n",
    "    # Generating a dataframe from the previous list\n",
    "    df2 = pd.DataFrame(cols2)\n",
    "\n",
    "    # Iterating over the dictionary to find similar items to the third word\n",
    "    for the_item in dictionary:\n",
    "        # Applying the 4-gram to the third misspelled word\n",
    "        set1 = get_ngrams_4(entries[2], 4)\n",
    "        \n",
    "        # Apllying the 4-gram to each item of the vocabulary of corrected words\n",
    "        set2 = get_ngrams_4(the_item, 4)\n",
    "        \n",
    "        # Calculating the Jaccard distance for each word\n",
    "        res = nltk.distance.jaccard_distance(set(set1),set(set2))\n",
    "        \n",
    "        # Appending the word and its respective distance to the list\n",
    "        cols3.append({\"word\": the_item, \"distance\": float(res.real)})\n",
    "        \n",
    "    # Generating a dataframe from the previous list\n",
    "    df3 = pd.DataFrame(cols3)\n",
    "        \n",
    "    # Appending the recommendation for each misspelled word to the result list\n",
    "    result_list = [df1.sort_values('distance')['word'].values[0],\n",
    "            df2.sort_values('distance')['word'].values[0],\n",
    "            df3.sort_values('distance')['word'].values[0]]\n",
    "    \n",
    "    # Returning the result list\n",
    "    return result_list\n",
    "\n",
    "recommender_jaccard_4_grams()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommender using Levenshtein distance\n",
    "\n",
    "For this recommender, your function should provide recommendations for the three default words provided above using the following distance metric:\n",
    "\n",
    "**[Edit distance on the two words with transpositions.](https://en.wikipedia.org/wiki/Damerau%E2%80%93Levenshtein_distance)**\n",
    "\n",
    "*This function should return a list of length three:\n",
    "`['cormulent_reccomendation', 'incendenece_reccomendation', 'validrate_reccomendation']`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['corpulent', 'intendence', 'validate']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def recommender_levenshtein(entries=['cormulent', 'incendenece', 'validrate']):\n",
    "    \n",
    "     '''\n",
    "        Description: This function receives three misspelled words and apply the Levenshtein distance with transpositions.\n",
    "        \n",
    "        Args:\n",
    "            - entries (list): a list of length three with the misspelled words\n",
    "        \n",
    "        Returns:\n",
    "            - result_list (list): a list of length three: ['cormulent_reccomendation', 'incendenece_reccomendation', 'validrate_reccomendation']\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # List to append recommendations for the first word\n",
    "    cols = []\n",
    "    \n",
    "    # List to append recommendations for the second word\n",
    "    cols2 = []\n",
    "    \n",
    "    # List to append recommendations for the third word\n",
    "    cols3 = []\n",
    "    \n",
    "     # Load the dictionary\n",
    "    dictionary = [w for w in correct_spellings if w[0].lower() == entries[0][0].lower() or w[0].lower() == entries[1][0].lower()\n",
    "                      or w[0].lower() == entries[2][0].lower()]\n",
    "    \n",
    "    # Iterating over the dictionary to find similar items to the fisrt word\n",
    "    for the_item in dictionary:\n",
    "        # Appending the word and its respective distance to the list\n",
    "        cols.append({\"word\": the_item, \"distance\": nltk.edit_distance(entries[0], the_item, transpositions=True)})\n",
    "        \n",
    "    # Generating a dataframe from the previous list\n",
    "    result1 = pd.DataFrame(cols)\n",
    "\n",
    "    # Iterating over the dictionary to find similar items to the second word\n",
    "    for the_item in dictionary:\n",
    "        # Appending the word and its respective distance to the list\n",
    "        cols2.append({\"word\": the_item, \"distance\": nltk.edit_distance(entries[1], the_item, transpositions=True)})\n",
    "        \n",
    "    # Generating a dataframe from the previous list\n",
    "    result2 = pd.DataFrame(cols2)\n",
    "\n",
    "    # Iterating over the dictionary to find similar items to the third word\n",
    "    for the_item in dictionary:\n",
    "        # Appending the word and its respective distance to the list\n",
    "        cols3.append({\"word\": the_item, \"distance\": nltk.edit_distance(entries[2], the_item, transpositions=True)})\n",
    "    \n",
    "    # Generating a dataframe from the previous list\n",
    "    result3 = pd.DataFrame(cols3)\n",
    "    \n",
    "    # Appending the recommendation for each misspelled word to the result list\n",
    "    result_list = [result1.sort_values('distance')['word'].values[0],\n",
    "             result2.sort_values('distance')['word'].values[0],\n",
    "             result3.sort_values('distance')['word'].values[0]] \n",
    "    \n",
    "    # Returning the result list\n",
    "    return result_list\n",
    "    \n",
    "recommender_levenshtein()"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-text-mining",
   "graded_item_id": "r35En",
   "launcher_item_id": "tCVfW",
   "part_id": "NTVgL"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
